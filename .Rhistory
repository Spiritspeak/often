#Generate help files
devtools::document()
#Build manual
devtools::build_manual(path=".")
#Check package
devtools::check(args="--as-cran")
#devtools::check_win_devel()
#build package
#devtools::build()
flist<-list.files(all.files=T)
if(length(flist)>0){
flist<- flist[grep("\\.Rd2.*",x=flist)]
unlink(flist,recursive=T)
}
#userfinder-reddit-only
for(pack in c("magrittr","dplyr","httr","stringr")){ require(pack,character.only=T) }
timescope = 14 * 24 * 60 * 60
contenttype = "submission"
subreddit = "dankleft"
threshold = 2
# funs ####
now<-function(){ round(as.numeric(Sys.time())) }
list2df<-function(li,include.sublists=T){
if(!include.sublists){
li%<>%lapply(FUN=function(x){x[sapply(x,length)<=1]})
}
if(length(li)>0){
newdf<-li[[1]]%>%unlist%>%t%>%as.data.frame(stringsAsFactors=F)%>%fixColNames()
if(length(li)>1){
for(i in 2:length(li)){
rowdat<-li[[i]]%>%unlist%>%t%>%as.data.frame(stringsAsFactors=F)%>%fixColNames()
rowdat[,setdiff(names(newdf), names(rowdat))] <- NA
newdf[,setdiff(names(rowdat), names(newdf))] <- NA
newdf<-rbind(newdf,rowdat)
}
}
}else{
newdf<-NULL
}
return(newdf)
}
fixColNames<-function(df){
nv<-colnames(df)
dupes<-unique(nv[duplicated(nv)])
for(p in dupes){
nv[nv==p]<-paste0(p,"_",seq_len(sum(nv==p)))
}
colnames(df)<-nv
return(df)
}
unevenrbind<-function(df1,df2){
if(nrow(df1)==0){
df2
}else if(nrow(df2) == 0){
df1
}else{
rbind(
data.frame(c(df1, sapply(setdiff(names(df2), names(df1)), function(x) NA)),stringsAsFactors=F),
data.frame(c(df2, sapply(setdiff(names(df1), names(df2)), function(x) NA)),stringsAsFactors=F),
stringsAsFactors=F
)
}
}
makeCounter<-function(){ ct<-0; function(){ return(ct<<-ct+1) } }
counter<-makeCounter()
# code ####
currdate<-now()
maxdate<-currdate-timescope
after<-""
counter<-makeCounter()
fulldata<-data.frame()[F,]
while(currdate>maxdate){
message("Now at page ",counter(),". Current date is ",currdate)
if(contenttype=="submission"){
currpage<- RETRY("GET",paste0("https://reddit.com/r/",subreddit,"/new.json?after=",after),
user_agent("ActiveUserFinder")) %>%
content() %$% data
}
if(contenttype=="comment"){
currpage<- RETRY("GET",paste0("https://reddit.com/r/",subreddit,"/comments.json?after=",after),
user_agent("ActiveUserFinder")) %>%
content() %$% data
}
after<-currpage$after
currposts<-currpage$children %>% lapply(FUN=function(x){ x$data }) %>% list2df()
currposts %<>% select(-contains("all_awardings"),-contains("preview"),
-contains("media"),-contains("flair"),-contains("gallery_data"))
fulldata %<>% unevenrbind(currposts)
newdate <- min(as.numeric(currposts$created))
if(newdate>currdate){ break }
currdate <- newdate
}
fulldata <- fulldata[!duplicated(fulldata$name),]
# analysis ####
if(contenttype=="submission"){
statists<- fulldata %>% group_by(author) %>%
summarise(count=n(),
directs=sum(is.na(crosspost_parent)),xposts=sum(!is.na(crosspost_parent)),
maxkarma=max(as.numeric(score)),avgkarma=mean(as.numeric(score)))
statists %>% arrange(desc(directs)) %>% filter(directs >=threshold) %>% pull(author) %>% cat(sep="\n")
#statists %>% arrange(desc(directs)) %>% filter(directs ==2) %>% pull(author) %>% cat(sep="\n")
}
if(contenttype=="comment"){
statists <- fulldata %>% group_by(author) %>%
summarise(count=n(),onposts=length(unique(link_id)),spread=count/onposts)
statists %>% arrange(desc(onposts)) %>% filter(onposts >= 10) %>% pull(author) %>% cat(sep="\n")
}
install.packages(c("backports", "digest", "dplyr", "expm", "fansi", "fs", "ggrepel", "glue", "hms", "htmltools", "httpuv", "magick", "Matrix", "ps", "Rcpp", "rlang", "roxygen2", "sass", "stringi", "testthat", "tibble"))
install.packages(c("backports", "digest", "dplyr", "expm", "fansi", "fs", "ggrepel", "glue", "hms", "htmltools", "httpuv", "magick", "Matrix", "ps", "Rcpp", "rlang", "roxygen2", "sass", "stringi", "testthat", "tibble"))
counter()
